{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ye0njinkim/EEE4178_2023_Hands_On/blob/main/2023_Day5_Transformer_fin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb6dC15BVlu7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9NUt9eMVlu-"
      },
      "source": [
        "\n",
        "# ``nn.Transformer`` 와 torchtext로 언어 번역하기\n",
        "\n",
        "이 튜토리얼에서는,\n",
        "    - Transformer(트랜스포머)를 사용한 번역 모델을 바닥부터 학습하는 방법을 배워보겠습니다.\n",
        "    - [Multi30k](http://www.statmt.org/wmt16/multimodal-task.html#task1)_\n",
        "      데이터셋을 사용하여 독일어(German)를 영어(English)로 번역하는 모델을 학습해보겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY6ust6BVlu_"
      },
      "source": [
        "## 데이터 구하고 처리하기\n",
        "\n",
        "[torchtext 라이브러리](https://pytorch.org/text/stable/)_\\ 에는 언어 번역 모델을\n",
        "생성하기 위한 데이터셋을 쉽게 만들 수 있는 도구들이 있습니다.\n",
        "이 튜토리얼에서는 torchtext의 내장(inbuilt) 데이터셋을 어떻게 사용하고,\n",
        "원시(raw) 텍스트 문장을 토큰화(tokenize)하고, 토큰을 텐서로 수치화하는 방법을\n",
        "살펴보겠습니다. 출발어(source)-도착어(target) 원시(raw) 문장을 생성하기 위해서는\n",
        "[torchtext 라이브러리의 Multi30k 데이터셋](https://pytorch.org/text/stable/datasets.html#multi30k)_\n",
        "을 사용하겠습니다.\n",
        "\n",
        "torchtext 데이터셋에 접근하기 전에, https://github.com/pytorch/data 을 참고하여 torchdata를 설치하시기 바랍니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWH-MKwEVlvA"
      },
      "source": [
        "출발어(source)와 목적어(target)의 토크나이저(tokenizer)를 생성합니다.\n",
        "아래 필요 사항(dependency)을 모두 설치해주세요.\n",
        "\n",
        "```python\n",
        "pip install -U torchdata\n",
        "pip install -U spacy\n",
        "python -m spacy download en_core_web_sm![positionalencoding.png](data:image/png;base64,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)\n",
        "python -m spacy download de_core_news_sm\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U torchdata"
      ],
      "metadata": {
        "id": "SMLqFOe8X74T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U spacy"
      ],
      "metadata": {
        "id": "HVaxIBlKX8U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pip install 하고 런타임 재시작 해야함"
      ],
      "metadata": {
        "id": "xJRdzzXGWNoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "subprocess.call(['python', '-m', 'spacy', 'download', 'de_core_news_sm'])"
      ],
      "metadata": {
        "id": "vmvDsVuwV341",
        "outputId": "fd483009-b7aa-4d1b-bdf6-eb9005311c71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "subprocess.call(['python', '-m', 'spacy', 'download', 'en_core_web_sm'])"
      ],
      "metadata": {
        "id": "jXpVvamHX4MJ",
        "outputId": "3ce32f5c-0132-49dc-8937-8e4321cf27e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall portalocker"
      ],
      "metadata": {
        "id": "VKQ47hNdYHr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f980abd8-d3a8-4588-a2ee-374138491dce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: portalocker 2.8.2\n",
            "Uninstalling portalocker-2.8.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/portalocker-2.8.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/portalocker/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled portalocker-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install portalocker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "QThiTVKx1hUH",
        "outputId": "6e373860-5d24-45c5-acc1-dae01bd14590"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "portalocker"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1RN1ltGJVlvA"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer #텍스트를 token화 하는데 사용\n",
        "from torchtext.vocab import build_vocab_from_iterator #Iterator로부터 vocabulary를 구축하는데에 사용\n",
        "from torchtext.datasets import multi30k, Multi30k #독일어 / 영어 문장 쌍을 포함하는 translation task를 위한 dataset\n",
        "from typing import Iterable, List #type hinting\n",
        "\n",
        "\n",
        "# 원본 데이터의 링크가 동작하지 않으므로 데이터셋의 URL을 수정해야 합니다.\n",
        "# 더 자세한 내용은 https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 을 참고해주세요.\n",
        "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
        "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
        "#URL 설정\n",
        "\n",
        "SRC_LANGUAGE = 'de' #source language\n",
        "TGT_LANGUAGE = 'en' #target language\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "#token과 vocabulary를 저장하기 위함."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "\n",
        "# 토큰 목록을 생성하기 위한 헬퍼(helper) 함수\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# 특수 기호(symbol)와 인덱스를 정의합니다\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# 토큰들이 어휘집(vocab)에 인덱스 순서대로 잘 삽입되어 있는지 확인합니다\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    # 학습용 데이터 반복자(iterator)\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    # torchtext의 Vocab(어휘집) 객체 생성\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)\n",
        "\n",
        "# ``UNK_IDX`` 를 기본 인덱스로 설정합니다. 이 인덱스는 토큰을 찾지 못하는 경우에 반환됩니다.\n",
        "# 만약 기본 인덱스를 설정하지 않으면 어휘집(Vocabulary)에서 토큰을 찾지 못하는 경우\n",
        "# ``RuntimeError`` 가 발생합니다.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "dG32arsx0Lz4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs4_3khpVlvB"
      },
      "source": [
        "## Transformer를 사용한 시퀀스-투-시퀀스(Seq2Seq) 신경망\n",
        "\n",
        "Transformer(트랜스포머)는 기계번역 작업(task)을 위해\n",
        "[\"Attention is all you need\"](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)_\n",
        "논문에 소개된 Seq2Seq 모델입니다.\n",
        "아래에서 Transformer를 사용한 Seq2Seq 신경망을 만들어보겠습니다.\n",
        "신경망은 세 부분으로 구성되는데, 첫번째 부분은 임베딩 계층(embedding layer)입니다.\n",
        "이 계층은 입력 인덱스의 텐서를 입력 임베딩의 해당하는 텐서로 변환합니다.\n",
        "이러한 임베딩은 입력 토큰의 위치 정보(position information)를 모델에 전달하기 위해\n",
        "위치 인코딩(positional encoding)을 추가합니다.\n",
        "두번째 부분은 실제 [Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)_ 모델입니다.\n",
        "마지막으로 Transformer 모델의 출력을 선형 계층에 통과시켜 도착어의 각 토큰에 대한 정규화되지 않은\n",
        "확률(un-normalized probability)로 제공합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #디바이스 GPU로"
      ],
      "metadata": {
        "id": "eITDLysvrnfY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/x19d3vq/positionalencoding.png\" alt=\"positionalencoding\" border=\"0\"></a>"
      ],
      "metadata": {
        "id": "x06h_arUrn9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 순서 개념(notion)을 토큰 임베딩에 도입하기 위한 위치 인코딩(positional encoding)을 위한 헬퍼 모듈(Module)\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):  #embedding 크기, dropout 비율, 최대 시퀀스 길이\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
      ],
      "metadata": {
        "id": "Yry0JZn4sIY0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 인덱스의 텐서를 해당하는 토큰 임베딩의 텐서로 변환하기 위한 헬퍼 모듈(Module)\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size): #vocabulary size, embedding size\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size) #embedding 뽑고 크기 조정"
      ],
      "metadata": {
        "id": "gcFC-RNitPiS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y2kwaCfzVlvB"
      },
      "outputs": [],
      "source": [
        "# Seq2Seq 신경망\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1): #인코더 디코더 layer(층)수, embedding 크기, head수(multi head), vocabulary size, feed-foward network 크기, dropout\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size) #embedding을 가지고 target vocabulary에서 어떤 단어인지 찾기 위함!\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrnsrqfFVlvC"
      },
      "source": [
        "학습하는 동안, 모델이 예측할 때 정답(이후 출현하는 단어)을 보지 못하도록 하는\n",
        "후속 단어 마스크(subsequent word mask)가 필요합니다. 또한, 출발어와 도착어의 패딩(padding) 토큰들\n",
        "또한 숨겨야 합니다. 아래에 두 가지 모두를 처리할 함수를 정의해보겠습니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WGFevhodVlvC"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz): #길이자 sz인 aequence에 대한 subsequent word mask\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1) #triu? -> 대각선 위의 요소는 1 아래는 0. 디코더가 미래의 단어를 보지 않도록.\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)) #mask가 0이면 -inf로. softmax 계산 시 해당 위치를 무시하게.\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len) #target sequence에 대한 후속 마스크 생성.\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool) # soruce sequence에 대한 마스크. 모든 값 0\n",
        "    #source sequence는 전체 내용 고려해야.\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1) #padding 식별\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fio12awVlvD"
      },
      "source": [
        "이제 모델의 매개변수를 정의하고 객체를 생성(instantiate)해보겠습니다.\n",
        "아래처럼 학습 단계에서 사용할 손실 함수(loss function)를 교차 엔트로피 손실(cross-entropy loss)로 정의하고,\n",
        "옵티마이저(optimizer)도 정의합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-bnoin78VlvD",
        "outputId": "e268cacc-08dd-4621-dc42-6f979610b4c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "#다른 시드도 고정해야 진짜 고정임..\n",
        "#seed everything 구글링.\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3 #parameter set\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "#초기화.\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GmprWO-VlvD"
      },
      "source": [
        "## 대조(Collation)\n",
        "\n",
        "위의 ``데이터 구하고 처리하기`` 장에서 봤듯이, 데이터 반복자(iterator)는 원시 문자열의 쌍을 생성합니다.\n",
        "이 문자열 쌍들을 이전에 정의한 ``Seq2Seq`` 신경망에서 처리할 수 있도록 텐서 묶음(batched tensor)으로 변환해야 합니다.\n",
        "이제 원시 문자열들의 묶음(batch)을 텐서 묶음으로 변환하여 모델에 직접 전달할 수 있도록 하는 대응어(collate) 함수를\n",
        "정의해보겠습니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "N-IGGgDpVlvD"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 순차적인 작업들을 하나로 묶는 헬퍼 함수\n",
        "def sequential_transforms(*transforms): #임의 개수의 변환함수를 인수로.\n",
        "    def func(txt_input): # 입력 텍스트에 대해 각 변환을 순차적으로 적용\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# BOS/EOS를 추가하고 입력 순서(sequence) 인덱스에 대한 텐서를 생성하는 함수 #BOS, 입력 토큰 ID, EOS 토큰 연결\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# 출발어(src)와 도착어(tgt) 원시 문자열들을 텐서 인덱스로 변환하는 변형(transform)\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], # 토큰화(Tokenization)\n",
        "                                               vocab_transform[ln], # 수치화(Numericalization) 단어를 그대로 사용할 수 없으니..\n",
        "                                               tensor_transform) # BOS/EOS를 추가하고 텐서를 생성\n",
        "\n",
        "\n",
        "# 데이터를 텐서로 조합(collate)하는 함수\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch: #배치 내의 데이터에 대해\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))) #줄바꿈 문자 제거\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX) #동일 길이 패딩\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_qxwA2KVlvE"
      },
      "source": [
        "각 에폭(epoch)마다 호출할 학습 및 검증(evaluation) 단계를 정의해보겠습니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "upM15lHAVlvE"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0 #loss 저장 변수\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in train_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :] #EOS 제외\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input) #마스크 생성\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask) #model foward 결과\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :] #실제 타겟 출력(EOS 제외)\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1)) #loss계산\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(train_dataloader))\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(val_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8es7XYfVlvE"
      },
      "source": [
        "이제 모델 학습을 위한 모든 요소가 준비되었습니다. 학습을 해보겠습니다!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OKDt09uRVlvE",
        "outputId": "6d729787-d36c-48aa-e932-efa24bff7fab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 5.344, Val loss: 4.106, Epoch time = 45.160s\n",
            "Epoch: 2, Train loss: 3.761, Val loss: 3.309, Epoch time = 43.432s\n",
            "Epoch: 3, Train loss: 3.157, Val loss: 2.887, Epoch time = 45.233s\n",
            "Epoch: 4, Train loss: 2.767, Val loss: 2.640, Epoch time = 43.585s\n",
            "Epoch: 5, Train loss: 2.477, Val loss: 2.442, Epoch time = 43.583s\n",
            "Epoch: 6, Train loss: 2.247, Val loss: 2.306, Epoch time = 44.818s\n",
            "Epoch: 7, Train loss: 2.055, Val loss: 2.207, Epoch time = 43.943s\n",
            "Epoch: 8, Train loss: 1.893, Val loss: 2.114, Epoch time = 43.542s\n",
            "Epoch: 9, Train loss: 1.754, Val loss: 2.054, Epoch time = 44.335s\n",
            "Epoch: 10, Train loss: 1.628, Val loss: 2.008, Epoch time = 44.395s\n",
            "Epoch: 11, Train loss: 1.520, Val loss: 1.961, Epoch time = 43.597s\n",
            "Epoch: 12, Train loss: 1.420, Val loss: 1.958, Epoch time = 43.500s\n",
            "Epoch: 13, Train loss: 1.330, Val loss: 1.972, Epoch time = 44.887s\n",
            "Epoch: 14, Train loss: 1.245, Val loss: 1.978, Epoch time = 43.406s\n",
            "Epoch: 15, Train loss: 1.173, Val loss: 1.929, Epoch time = 43.546s\n",
            "Epoch: 16, Train loss: 1.103, Val loss: 1.901, Epoch time = 43.831s\n",
            "Epoch: 17, Train loss: 1.035, Val loss: 1.912, Epoch time = 44.624s\n",
            "Epoch: 18, Train loss: 0.973, Val loss: 1.927, Epoch time = 43.558s\n"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 18\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "\n",
        "# 탐욕(greedy) 알고리즘을 사용하여 출력 순서(sequence)를 생성하는 함수\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask) #data encoding\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE) #start symbol로 초기화된 target sequence 생성\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0)) #target mask 생성\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask) #현재 target sequence에 대한 출력을 decoder로 생성\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1]) #가장 최근에 생성된 단어에 대한 예측 확률 계산(linear layer 결과)\n",
        "        _, next_word = torch.max(prob, dim=1) #제일 높은 확률 선택\n",
        "        next_word = next_word.item() #선택 단어 현재 시퀀스에 추가\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys #ys에 순서대로 채우고 return\n",
        "\n",
        "\n",
        "# 입력 문장을 도착어로 번역하는 함수\n",
        "def translate(model: torch.nn.Module, src_sentence: str): #greedy decode로 실제 model의 출력을 문장으로 변환\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\") #eos, bos 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oBrS9A9uVlvE",
        "outputId": "415fa7c5-6b67-417f-983a-0ed1a4a8a0a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A group of people standing in front of an igloo \n"
          ]
        }
      ],
      "source": [
        "print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqGquuBeVlvF"
      },
      "source": [
        "## 참고자료\n",
        "\n",
        "1. Attention is all you need 논문.\n",
        "   https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
        "2. Transformer에 대한 설명. https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}